# 个人中期报告

## 课程总结

事实上，我是在没有任何 AI 基础的情况下参加的这个特训营的。鉴于这个课程相对于理论部分来说实践部分的占比要多得多，因此我需要在学习使用 AI 相关工具的同时，了解它们的运行原理，这样才能确切地知道自己在干什么。

在这十几天中，我将对机器学习的相关知识作系统的初步了解，同时结合每天对于各种模型的使用实践，逐渐深入对机器学习相关方面的了解，并增强自己使用机器学习相关模型解决具体问题的能力。我将与课程内容与吴恩达的机器学习相关课程进行结合，在理论和实践上对 AI 及机器学习做了解。

目前我通过在 ModelScope 平台上的实操，已经初步了解了 CNN、Transformer、GAN 等模型的运作原理，并且已经在 ModelScope 提供的 Notebook 上使用和训练了用于图像分类、图像检测、人脸检测的各种模型，并成功运用它们解决了相对应的实际问题。

关于 FaceChain，在经过几个小时的对于前置知识的高速学习之后我大致了解了 FaceChain 的工作原理。简单来说，FaceChain 所使用的两个 LoRA 模型分别指导模型“画谁”和“怎么画”，而我们的任务是调一个后者的 LoRA 模型出来，并且需要有能用的效果。

## 工作总结与计划

我的队友在 LoRA 即插即用等应用逻辑方面工作，与此同时我负责训练一些 LoRA 模型。

为了给 FaceChain 增加新的风格，我针对其中的 MajicmixRealistic_v6 模型测试与微调了十余种 LoRA 风格模型，最终筛选出古风（traditional Chinese Style）、壮族服装风（zhuangzu）和欧式田野风（european fields）三个风格模型与其对应权重与提示词，可以与 FaceChain 的模型良好地协同工作。[目前已被 merge](https://github.com/modelscope/facechain/pull/189)。

目前看起来 FaceChain 的一些急需添加的功能已经完成，接下来的工作主要是协助队友扩展 FaceChain 功能。事实上我还急切地需要学习 Gradio 的逻辑。

接下来我们小组可能的工作部分还有：

**更友好的自定义姿态逻辑**。现在 FaceChain 有一个可以通过上传图片来识别图片内的人物姿态，进而让生成图片也有相应姿态的功能。这主要使用了 Controlnet 等技术实现。不过有时候用户自己可能没有相应图片可以上传，这时可以让用户（直接通过 Gradio 的 UI）绘制姿态，从而免去还要找张图片的麻烦。**目前正在尝试**。可能先实现一个让用户能直接上传 keypose 图片的功能。

**基于 Mix-of-Show 重构 FaceChain 的实现方式**。Mix-of-Show 提供了一种基于 ED-LoRA 的 LoRA 学习和合并方式，理论上可以在多人物融合的任务上有更好的效果。**目前正在考虑可行性**。因为 ED-LoRA 和 LoRA 实际上完全不是一个东西，因此由于训练和合并的逻辑不一致，在代码上势必有相当大规模的改动，或者说，重写。不保证可以在短学期课程结束前完成。
